"""
PyTorch Dataset and DataLoader utilities for ARC-3 state transition data.

This module provides:
- TransitionDataset: PyTorch Dataset for loading generated .npz files
- Helper functions for batching and data transformations
- Support for multiple dataset files (multi-game training)

Example usage:
    from agents.dataset import TransitionDataset, create_dataloader

    # Single game dataset
    dataset = TransitionDataset("datasets/ls20_20241201.npz")

    # Multi-game dataset
    dataset = TransitionDataset.from_multiple([
        "datasets/ls20_20241201.npz",
        "datasets/other_game_20241201.npz",
    ])

    # Create DataLoader
    dataloader = create_dataloader(dataset, batch_size=64, shuffle=True)

    for batch in dataloader:
        before_states = batch["before_state"]  # (B, 16, 64, 64) one-hot
        after_states = batch["after_state"]    # (B, 16, 64, 64) one-hot
        actions = batch["action"]              # (B,) action indices
        changed = batch["changed"]             # (B,) boolean
        ...
"""

import glob
import json
from pathlib import Path
from typing import Optional, Union

import numpy as np
import torch
from torch.utils.data import Dataset, DataLoader, ConcatDataset


class TransitionDataset(Dataset):
    """PyTorch Dataset for ARC-3 state transitions."""

    NUM_COLORS = 16
    GRID_SIZE = 64

    def __init__(
        self,
        npz_path: str,
        one_hot_encode: bool = True,
        filter_changed_only: bool = False,
        include_sequences: bool = False,
    ):
        """
        Load a transition dataset from a .npz file.

        Args:
            npz_path: Path to the .npz file generated by generate_dataset.py
            one_hot_encode: Whether to one-hot encode the grid states (16 channels)
            filter_changed_only: Only include transitions where state changed
            include_sequences: Include move sequence data (variable length, slower)
        """
        self.npz_path = npz_path
        self.one_hot_encode = one_hot_encode
        self.include_sequences = include_sequences

        # Load data
        data = np.load(npz_path, allow_pickle=True)

        self.game_ids = data["game_id"]
        self.move_nums = data["move_num"]
        self.move_types = data["move_type"]
        self.moves = data["move"]
        self.changed = data["board_state_changed"]
        self.solutions = data["solution_boolean"]
        self.hashes = data["after_board_state_hash"]
        self.scores_before = data["score_before"]
        self.scores_after = data["score_after"]

        # Board states: (N, 4096) -> (N, 64, 64)
        self.before_states = data["before_board_state"].reshape(-1, self.GRID_SIZE, self.GRID_SIZE)
        self.after_states = data["after_board_state"].reshape(-1, self.GRID_SIZE, self.GRID_SIZE)

        if include_sequences:
            self.move_sequences = data["prev_move_sequences"]
        else:
            self.move_sequences = None

        # Load stats if available
        if "stats" in data:
            self.stats = json.loads(str(data["stats"][0]))
        else:
            self.stats = {}

        # Filter if requested
        if filter_changed_only:
            mask = self.changed
            self.game_ids = self.game_ids[mask]
            self.move_nums = self.move_nums[mask]
            self.move_types = self.move_types[mask]
            self.moves = self.moves[mask]
            self.changed = self.changed[mask]
            self.solutions = self.solutions[mask]
            self.hashes = self.hashes[mask]
            self.scores_before = self.scores_before[mask]
            self.scores_after = self.scores_after[mask]
            self.before_states = self.before_states[mask]
            self.after_states = self.after_states[mask]
            if self.move_sequences is not None:
                self.move_sequences = self.move_sequences[mask]

        # Create action mapping (ACTION1=1 -> index 0, etc.)
        self.action_to_idx = {1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 7: 5}
        self.idx_to_action = {v: k for k, v in self.action_to_idx.items()}
        self.num_actions = 6

    def __len__(self) -> int:
        return len(self.moves)

    def _to_one_hot(self, grid: np.ndarray) -> torch.Tensor:
        """Convert grid (64, 64) with values 0-15 to one-hot (16, 64, 64)."""
        tensor = torch.zeros(self.NUM_COLORS, self.GRID_SIZE, self.GRID_SIZE, dtype=torch.float32)
        grid_tensor = torch.from_numpy(grid.astype(np.int64))
        tensor.scatter_(0, grid_tensor.unsqueeze(0), 1)
        return tensor

    def __getitem__(self, idx: int) -> dict:
        """Get a single transition."""
        before_grid = self.before_states[idx]
        after_grid = self.after_states[idx]

        if self.one_hot_encode:
            before_state = self._to_one_hot(before_grid)
            after_state = self._to_one_hot(after_grid)
        else:
            before_state = torch.from_numpy(before_grid.astype(np.float32))
            after_state = torch.from_numpy(after_grid.astype(np.float32))

        # Convert action ID to index
        action_id = int(self.moves[idx])
        action_idx = self.action_to_idx.get(action_id, 0)

        result = {
            "before_state": before_state,
            "after_state": after_state,
            "action": torch.tensor(action_idx, dtype=torch.long),
            "action_id": torch.tensor(action_id, dtype=torch.long),
            "changed": torch.tensor(self.changed[idx], dtype=torch.float32),
            "solution": torch.tensor(self.solutions[idx], dtype=torch.float32),
            "score_before": torch.tensor(self.scores_before[idx], dtype=torch.float32),
            "score_after": torch.tensor(self.scores_after[idx], dtype=torch.float32),
            "score_delta": torch.tensor(
                self.scores_after[idx] - self.scores_before[idx], dtype=torch.float32
            ),
            "move_num": torch.tensor(self.move_nums[idx], dtype=torch.long),
        }

        if self.include_sequences and self.move_sequences is not None:
            # Variable length - will need custom collate for batching
            result["move_sequence"] = torch.tensor(
                self.move_sequences[idx], dtype=torch.long
            )

        return result

    @classmethod
    def from_multiple(
        cls,
        npz_paths: list[str],
        **kwargs,
    ) -> ConcatDataset:
        """
        Create a combined dataset from multiple .npz files.

        Args:
            npz_paths: List of paths to .npz files
            **kwargs: Arguments passed to TransitionDataset

        Returns:
            ConcatDataset combining all files
        """
        datasets = [cls(path, **kwargs) for path in npz_paths]
        return ConcatDataset(datasets)

    @classmethod
    def from_directory(
        cls,
        directory: str,
        pattern: str = "*.npz",
        **kwargs,
    ) -> ConcatDataset:
        """
        Create a combined dataset from all .npz files in a directory.

        Args:
            directory: Directory containing .npz files
            pattern: Glob pattern for matching files
            **kwargs: Arguments passed to TransitionDataset

        Returns:
            ConcatDataset combining all matching files
        """
        paths = sorted(glob.glob(str(Path(directory) / pattern)))
        if not paths:
            raise ValueError(f"No files matching {pattern} found in {directory}")
        return cls.from_multiple(paths, **kwargs)

    def get_class_weights(self, target: str = "changed") -> torch.Tensor:
        """
        Compute class weights for imbalanced classification.

        Args:
            target: Which target to compute weights for ("changed" or "solution")

        Returns:
            Tensor of class weights [weight_negative, weight_positive]
        """
        if target == "changed":
            labels = self.changed
        elif target == "solution":
            labels = self.solutions
        else:
            raise ValueError(f"Unknown target: {target}")

        n_positive = labels.sum()
        n_negative = len(labels) - n_positive
        n_total = len(labels)

        if n_positive == 0 or n_negative == 0:
            return torch.tensor([1.0, 1.0])

        weight_positive = n_total / (2 * n_positive)
        weight_negative = n_total / (2 * n_negative)

        return torch.tensor([weight_negative, weight_positive], dtype=torch.float32)


class TransitionPredictionDataset(TransitionDataset):
    """
    Dataset for training forward dynamics models.

    Returns (state, action) -> next_state pairs suitable for
    training models that predict state transitions.
    """

    def __getitem__(self, idx: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """
        Get a (state, action, next_state) triple.

        Returns:
            Tuple of (before_state, action_one_hot, after_state)
        """
        item = super().__getitem__(idx)

        # Create one-hot action encoding
        action_one_hot = torch.zeros(self.num_actions, dtype=torch.float32)
        action_one_hot[item["action"]] = 1.0

        return item["before_state"], action_one_hot, item["after_state"]


class ActionPredictionDataset(TransitionDataset):
    """
    Dataset for training action prediction models.

    Returns (state, action) -> changed pairs suitable for
    training models that predict which actions cause state changes.
    """

    def __getitem__(self, idx: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """
        Get a (state, action, changed) triple.

        Returns:
            Tuple of (before_state, action_index, changed_label)
        """
        item = super().__getitem__(idx)
        return item["before_state"], item["action"], item["changed"]


def create_dataloader(
    dataset: Dataset,
    batch_size: int = 64,
    shuffle: bool = True,
    num_workers: int = 0,
    pin_memory: bool = True,
    drop_last: bool = False,
) -> DataLoader:
    """
    Create a DataLoader for a transition dataset.

    Args:
        dataset: TransitionDataset or ConcatDataset
        batch_size: Batch size
        shuffle: Whether to shuffle data
        num_workers: Number of worker processes (0 for main process)
        pin_memory: Pin memory for faster GPU transfer
        drop_last: Drop last incomplete batch

    Returns:
        DataLoader instance
    """
    return DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=shuffle,
        num_workers=num_workers,
        pin_memory=pin_memory and torch.cuda.is_available(),
        drop_last=drop_last,
    )


def get_dataset_info(npz_path: str) -> dict:
    """
    Get summary information about a dataset file.

    Args:
        npz_path: Path to .npz file

    Returns:
        Dictionary with dataset statistics
    """
    data = np.load(npz_path, allow_pickle=True)

    info = {
        "path": npz_path,
        "n_transitions": len(data["move"]),
        "n_changed": int(data["board_state_changed"].sum()),
        "n_solutions": int(data["solution_boolean"].sum()),
        "unique_games": list(set(data["game_id"])),
        "action_distribution": {},
    }

    # Count action distribution
    for action_id in [1, 2, 3, 4, 5, 7]:
        count = int((data["move"] == action_id).sum())
        if count > 0:
            info["action_distribution"][f"ACTION{action_id}"] = count

    # Load stats if available
    if "stats" in data:
        info["generation_stats"] = json.loads(str(data["stats"][0]))

    return info
